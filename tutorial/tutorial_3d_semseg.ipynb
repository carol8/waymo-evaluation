{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Waymo Open Dataset 3D Semantic Segmentation Tutorial.ipynb",
      "provenance": [
        {
          "file_id": "tutorial.ipynb",
          "timestamp": 1644287712198
        }
      ],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "#Waymo Open Dataset 3D Semantic Segmentation Tutorial\n",
        "\n",
        "- Website: https://waymo.com/open\n",
        "- GitHub: https://github.com/waymo-research/waymo-open-dataset\n",
        "\n",
        "This tutorial demonstrates how to decode and interpret the 3D semantic segmentation labels. Visit the [Waymo Open Dataset Website](https://waymo.com/open) to download the full dataset.\n",
        "\n",
        "To use, open this notebook in [Colab](https://colab.research.google.com).\n",
        "\n",
        "Uncheck the box \"Reset all runtimes before running\" if you run this colab directly from the remote kernel. Alternatively, you can make a copy before trying to run it by following \"File > Save copy in Drive ...\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Installation"
      ],
      "metadata": {
        "id": "1sPLur9kMaLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Package installation\n",
        "Please follow the instructions in [tutorial.ipynb](https://github.com/waymo-research/waymo-open-dataset/blob/master/tutorial/tutorial.ipynb)."
      ],
      "metadata": {
        "id": "iEsf_G5_MeS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and global definitions"
      ],
      "metadata": {
        "id": "rqs8_62VNc4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data location. Please edit.\n",
        "\n",
        "# A tfrecord containing tf.Example protos as downloaded from the Waymo dataset\n",
        "# webpage.\n",
        "\n",
        "# Replace this path with your own tfrecords.\n",
        "FILENAME = '/content/waymo-od/tutorial/.../tfexample.tfrecord'"
      ],
      "metadata": {
        "id": "YuNAlbQpNkLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from waymo_open_dataset.utils import  frame_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset"
      ],
      "metadata": {
        "id": "xCDNLdp9Ni8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibor0U9XBlX6"
      },
      "source": [
        "# Read 3D semantic segmentation labels from Frame proto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "for data in dataset:\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    if frame.lasers[0].ri_return1.segmentation_label_compressed:\n",
        "      break"
      ],
      "metadata": {
        "id": "O41R3lljM9Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(frame.context.name)\n",
        "print(frame.context.stats)"
      ],
      "metadata": {
        "id": "opFz4B9JXC7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHK95_JBUXUx"
      },
      "source": [
        "(range_images, camera_projections, segmentation_labels,\n",
        " range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(\n",
        "    frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(segmentation_labels[open_dataset.LaserName.TOP][0].shape.dims)"
      ],
      "metadata": {
        "id": "fgCDPt9zeV_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Segmentation Labels in Range Images"
      ],
      "metadata": {
        "id": "T4tCSnwFR3uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(64, 20))\n",
        "def plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n",
        "  \"\"\"Plots range image.\n",
        "\n",
        "  Args:\n",
        "    data: range image data\n",
        "    name: the image title\n",
        "    layout: plt layout\n",
        "    vmin: minimum value of the passed data\n",
        "    vmax: maximum value of the passed data\n",
        "    cmap: color map\n",
        "  \"\"\"\n",
        "  plt.subplot(*layout)\n",
        "  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "  plt.title(name)\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "\n",
        "def get_semseg_label_image(laser_name, return_index):\n",
        "  \"\"\"Returns semseg label image given a laser name and its return index.\"\"\"\n",
        "  return segmentation_labels[laser_name][return_index]\n",
        "\n",
        "def show_semseg_label_image(semseg_label_image, layout_index_start = 1):\n",
        "  \"\"\"Shows range image.\n",
        "\n",
        "  Args:\n",
        "    show_semseg_label_image: the semseg label data of type MatrixInt32.\n",
        "    layout_index_start: layout offset\n",
        "  \"\"\"\n",
        "  semseg_label_image_tensor = tf.convert_to_tensor(semseg_label_image.data)\n",
        "  semseg_label_image_tensor = tf.reshape(\n",
        "      semseg_label_image_tensor, semseg_label_image.shape.dims)\n",
        "  instance_id_image = semseg_label_image_tensor[...,0] \n",
        "  semantic_class_image = semseg_label_image_tensor[...,1]\n",
        "  plot_range_image_helper(instance_id_image.numpy(), 'instance id',\n",
        "                   [8, 1, layout_index_start], vmin=-1, vmax=200, cmap='Paired')\n",
        "  plot_range_image_helper(semantic_class_image.numpy(), 'semantic class',\n",
        "                   [8, 1, layout_index_start + 1], vmin=0, vmax=22, cmap='tab20')\n",
        "\n",
        "frame.lasers.sort(key=lambda laser: laser.name)\n",
        "show_semseg_label_image(get_semseg_label_image(open_dataset.LaserName.TOP, 0), 1)\n",
        "show_semseg_label_image(get_semseg_label_image(open_dataset.LaserName.TOP, 1), 3)"
      ],
      "metadata": {
        "id": "yRE_3QhMR7KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Point Cloud Conversion and Visualization"
      ],
      "metadata": {
        "id": "C097jvXXR71D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_range_image_to_point_cloud_labels(frame,\n",
        "                                              range_images,\n",
        "                                              segmentation_labels,\n",
        "                                              ri_index=0):\n",
        "  \"\"\"Convert segmentation labels from range images to point clouds.\n",
        "\n",
        "  Args:\n",
        "    frame: open dataset frame\n",
        "    range_images: A dict of {laser_name, [range_image_first_return,\n",
        "       range_image_second_return]}.\n",
        "    segmentation_labels: A dict of {laser_name, [range_image_first_return,\n",
        "       range_image_second_return]}.\n",
        "    ri_index: 0 for the first return, 1 for the second return.\n",
        "\n",
        "  Returns:\n",
        "    point_labels: {[N, 2]} list of 3d lidar points's segmentation labels. 0 for\n",
        "      points that are not labeled.\n",
        "  \"\"\"\n",
        "  calibrations = sorted(frame.context.laser_calibrations, key=lambda c: c.name)\n",
        "  point_labels = []\n",
        "  for c in calibrations:\n",
        "    range_image = range_images[c.name][ri_index]\n",
        "    range_image_tensor = tf.reshape(\n",
        "        tf.convert_to_tensor(range_image.data), range_image.shape.dims)\n",
        "    range_image_mask = range_image_tensor[..., 0] > 0\n",
        "\n",
        "    if c.name in segmentation_labels:\n",
        "      sl = segmentation_labels[c.name][ri_index]\n",
        "      sl_tensor = tf.reshape(tf.convert_to_tensor(sl.data), sl.shape.dims)\n",
        "      sl_points_tensor = tf.gather_nd(sl_tensor, tf.where(range_image_mask))\n",
        "    else:\n",
        "      sl_points_tensor = tf.zeros([points_tensor.shape[0], 2], dtype=tf.int32)\n",
        "      \n",
        "    point_labels.append(sl_points_tensor.numpy())\n",
        "  return point_labels"
      ],
      "metadata": {
        "id": "QI56Rt1BPuOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame, range_images, camera_projections, range_image_top_pose)\n",
        "points_ri2, cp_points_ri2) = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame, range_images, camera_projections, range_image_top_pose, ri_index=1)"
      ],
      "metadata": {
        "id": "PSAbxSW0RAQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point_labels = convert_range_image_to_point_cloud_labels(\n",
        "    frame, range_images, segmentation_labels)\n",
        "point_labels_ri2 = convert_range_image_to_point_cloud_labels(\n",
        "    frame, range_images, segmentation_labels, ri_index=1)"
      ],
      "metadata": {
        "id": "jgUcnL9IRMZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3d points in vehicle frame.\n",
        "points_all = np.concatenate(points, axis=0)\n",
        "points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
        "# point labels.\n",
        "point_labels_all = np.concatenate(point_labels, axis=0)\n",
        "point_labels_all_ri2 = np.concatenate(point_labels_ri2, axis=0)\n",
        "# camera projection corresponding to each point.\n",
        "cp_points_all = np.concatenate(cp_points, axis=0)\n",
        "cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)"
      ],
      "metadata": {
        "id": "FdYRcWdRRWmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCj3SDbuq9Nr"
      },
      "source": [
        "###Show colored point cloud\n",
        "Example of rendered point clouds (this tutorial does not have visualization capability)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VFnGnOq6cO"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image('/content/waymo-od/tutorial/3d_semseg_points.png'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
